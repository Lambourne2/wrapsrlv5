{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WrapsRL v5: StyleGAN2-ADA for Rocket League Decal Textures\n",
    "\n",
    "This notebook implements a texture generation model for Rocket League decals using StyleGAN2-ADA PyTorch. The model is designed to generate high-quality 1024×1024 decal textures that respect the constraints of texture mapping in the game.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Rocket League decal textures present unique challenges for image generation models:\n",
    "- Specific regions must be preserved (large black spaces that should be left blank)\n",
    "- Texture mapping constraints must be respected\n",
    "- The model must be creative within these bounds\n",
    "\n",
    "This notebook addresses these challenges by:\n",
    "1. Setting up the appropriate environment for training on Google Colab with A100 GPU\n",
    "2. Preparing data from the provided Google Drive link using TFRecords\n",
    "3. Training a StyleGAN2-ADA PyTorch model with optimal parameters\n",
    "4. Evaluating the model using FID and precision/recall metrics\n",
    "5. Generating sample 1024×1024 decal textures\n",
    "\n",
    "The notebook also includes integration with Weights & Biases (wandb.ai) for remote monitoring of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup for Google Colab A100\n",
    "\n",
    "This section sets up the environment for training on Google Colab with an A100 GPU. It includes:\n",
    "- Mounting Google Drive\n",
    "- Installing required dependencies\n",
    "- Setting up system monitoring\n",
    "- Configuring GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab, setting up environment...\")\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set project paths\n",
    "    import os\n",
    "    PROJECT_ROOT = '/content/WrapsRL_v5'\n",
    "    DATA_DIR = f\"{PROJECT_ROOT}/data\"\n",
    "    MODELS_DIR = f\"{PROJECT_ROOT}/models\"\n",
    "    OUTPUTS_DIR = f\"{PROJECT_ROOT}/outputs\"\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(PROJECT_ROOT, exist_ok=True)\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "    os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
    "    \n",
    "    # Clone StyleGAN2-ADA PyTorch repository\n",
    "    !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git\n",
    "    %cd stylegan2-ada-pytorch\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "    !pip install wandb  # For remote monitoring\n",
    "    \n",
    "    # Check GPU availability and select A100\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"Not running in Colab. Please run this notebook in Google Colab with A100 GPU for optimal performance.\")\n",
    "    PROJECT_ROOT = os.getcwd()\n",
    "    DATA_DIR = os.path.join(PROJECT_ROOT, 'data')\n",
    "    MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "    OUTPUTS_DIR = os.path.join(PROJECT_ROOT, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up system monitoring\n",
    "if IN_COLAB:\n",
    "    # Install and import libraries for monitoring\n",
    "    !pip install psutil gputil\n",
    "    import psutil\n",
    "    import GPUtil\n",
    "    import time\n",
    "    from IPython.display import display, HTML\n",
    "    import threading\n",
    "    \n",
    "    # Function to monitor system resources\n",
    "    def monitor_resources():\n",
    "        while monitoring_active:\n",
    "            # CPU usage\n",
    "            cpu_percent = psutil.cpu_percent(interval=1)\n",
    "            \n",
    "            # Memory usage\n",
    "            memory = psutil.virtual_memory()\n",
    "            memory_percent = memory.percent\n",
    "            \n",
    "            # GPU usage\n",
    "            gpus = GPUtil.getGPUs()\n",
    "            if gpus:\n",
    "                gpu = gpus[0]\n",
    "                gpu_name = gpu.name\n",
    "                gpu_load = gpu.load * 100\n",
    "                gpu_memory_used = gpu.memoryUsed\n",
    "                gpu_memory_total = gpu.memoryTotal\n",
    "                gpu_memory_percent = (gpu_memory_used / gpu_memory_total) * 100\n",
    "                \n",
    "                print(f\"CPU: {cpu_percent:.1f}% | Memory: {memory_percent:.1f}% | \"\n",
    "                      f\"GPU: {gpu_name} | GPU Load: {gpu_load:.1f}% | \"\n",
    "                      f\"GPU Memory: {gpu_memory_used:.0f}/{gpu_memory_total:.0f} MB ({gpu_memory_percent:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"CPU: {cpu_percent:.1f}% | Memory: {memory_percent:.1f}% | GPU: Not available\")\n",
    "                \n",
    "            time.sleep(10)  # Update every 10 seconds\n",
    "    \n",
    "    # Start monitoring in a separate thread\n",
    "    monitoring_active = True\n",
    "    monitor_thread = threading.Thread(target=monitor_resources)\n",
    "    monitor_thread.daemon = True\n",
    "    monitor_thread.start()\n",
    "    \n",
    "    print(\"System monitoring started. Updates will appear every 10 seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Weights & Biases for remote monitoring\n",
    "import wandb\n",
    "\n",
    "# Initialize wandb - you'll need to log in with your API key\n",
    "!wandb login\n",
    "\n",
    "# Initialize a new wandb project\n",
    "wandb.init(\n",
    "    project=\"WrapsRL-v5\",\n",
    "    name=\"stylegan2-ada-rl-decals\",\n",
    "    config={\n",
    "        \"architecture\": \"StyleGAN2-ADA\",\n",
    "        \"dataset\": \"Rocket League Decals\",\n",
    "        \"batch_size\": 4,\n",
    "        \"augmentation\": \"ada\",\n",
    "        \"fp32\": True,\n",
    "        \"kimg\": 25000,\n",
    "        \"image_size\": 1024,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion and TFRecords Preparation\n",
    "\n",
    "This section handles data ingestion from the provided Google Drive link and prepares TFRecords for training. It includes:\n",
    "- Downloading data from Google Drive\n",
    "- Processing and preparing the dataset\n",
    "- Converting to TFRecords format for StyleGAN2-ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download data from Google Drive\n",
    "if IN_COLAB:\n",
    "    # The provided Google Drive link\n",
    "    DRIVE_LINK = \"https://drive.google.com/drive/folders/1--hKMnum6Y6vmzkDVzLvE44eYjRswvXG?usp=drive_link\"\n",
    "    \n",
    "    # Install gdown for downloading from Google Drive\n",
    "    !pip install gdown\n",
    "    \n",
    "    # Extract folder ID from the link\n",
    "    import re\n",
    "    folder_id = re.search(r'folders/([^?]+)', DRIVE_LINK).group(1)\n",
    "    \n",
    "    # Download the folder contents\n",
    "    !gdown --folder --id {folder_id} -O {DATA_DIR}/raw\n",
    "    \n",
    "    print(f\"Downloaded data to {DATA_DIR}/raw\")\n",
    "    !ls -la {DATA_DIR}/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process and prepare the dataset\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create processed data directory\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Function to process images\n",
    "def process_images(input_dir, output_dir, target_size=(1024, 1024)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(input_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    print(f\"Processing {len(image_files)} images...\")\n",
    "    \n",
    "    for img_file in tqdm(image_files):\n",
    "        try:\n",
    "            # Open and process image\n",
    "            img_path = os.path.join(input_dir, img_file)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Resize to target size if needed\n",
    "            if img.size != target_size:\n",
    "                img = img.resize(target_size, Image.LANCZOS)\n",
    "            \n",
    "            # Save as PNG\n",
    "            output_path = os.path.join(output_dir, os.path.splitext(img_file)[0] + '.png')\n",
    "            img.save(output_path, 'PNG')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "    \n",
    "    print(f\"Processed images saved to {output_dir}\")\n",
    "\n",
    "# Process the raw images\n",
    "RAW_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "if os.path.exists(RAW_DIR):\n",
    "    process_images(RAW_DIR, PROCESSED_DIR)\n",
    "else:\n",
    "    print(f\"Raw data directory {RAW_DIR} not found. Please ensure data is downloaded correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert processed images to StyleGAN2-ADA dataset format\n",
    "if IN_COLAB and os.path.exists(PROCESSED_DIR):\n",
    "    # Create dataset directory\n",
    "    DATASET_DIR = os.path.join(DATA_DIR, 'dataset')\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "    \n",
    "    # Use StyleGAN2-ADA's dataset_tool.py to create the dataset\n",
    "    !python stylegan2-ada-pytorch/dataset_tool.py create_from_images \\\n",
    "        {DATASET_DIR}/rocket_league_decals {PROCESSED_DIR}\n",
    "    \n",
    "    print(f\"Dataset created at {DATASET_DIR}/rocket_league_decals\")\n",
    "    \n",
    "    # Generate dataset statistics\n",
    "    import json\n",
    "    \n",
    "    # Count images\n",
    "    num_images = len([f for f in os.listdir(PROCESSED_DIR) \n",
    "                     if f.lower().endswith('.png')])\n",
    "    \n",
    "    # Calculate average file size\n",
    "    total_size = sum(os.path.getsize(os.path.join(PROCESSED_DIR, f)) \n",
    "                     for f in os.listdir(PROCESSED_DIR) \n",
    "                     if f.lower().endswith('.png'))\n",
    "    avg_size = total_size / num_images if num_images > 0 else 0\n",
    "    \n",
    "    # Save statistics\n",
    "    stats = {\n",
    "        \"num_images\": num_images,\n",
    "        \"image_size\": \"1024x1024\",\n",
    "        \"total_size_mb\": total_size / (1024 * 1024),\n",
    "        \"avg_size_kb\": avg_size / 1024\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'dataset_stats.json'), 'w') as f:\n",
    "        json.dump(stats, f, indent=4)\n",
    "    \n",
    "    print(\"Dataset statistics:\")\n",
    "    print(json.dumps(stats, indent=4))\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\"dataset_stats\": stats})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training with StyleGAN2-ADA PyTorch\n",
    "\n",
    "This section sets up and runs the training process using StyleGAN2-ADA PyTorch. It includes:\n",
    "- Selecting an appropriate pretrained model as a starting point\n",
    "- Configuring training parameters\n",
    "- Running the training process\n",
    "- Monitoring training progress with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download pretrained models\n",
    "if IN_COLAB:\n",
    "    # Create models directory\n",
    "    os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "    \n",
    "    # Download recommended pretrained models\n",
    "    pretrained_models = {\n",
    "        \"ffhq\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\",\n",
    "        \"metfaces\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl\",\n",
    "        \"afhqv2\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqv2.pkl\",\n",
    "        \"brecahad\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl\"\n",
    "    }\n",
    "    \n",
    "    for name, url in pretrained_models.items():\n",
    "        output_path = os.path.join(MODELS_DIR, f\"{name}.pkl\")\n",
    "        !wget {url} -O {output_path}\n",
    "        print(f\"Downloaded {name} model to {output_path}\")\n",
    "    \n",
    "    # List available models\n",
    "    print(\"\\nAvailable pretrained models:\")\n",
    "    !ls -la {MODELS_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model Selection\n",
    "\n",
    "Based on our research, we recommend the following pretrained models as potential kickoff points for Rocket League decal textures:\n",
    "\n",
    "1. **BreCaHAD (512x512)**: This medical dataset model has learned to generate images with specific structural constraints, which might transfer well to the constraints of texture mapping in Rocket League decals.\n",
    "\n",
    "2. **FFHQ (1024x1024)**: While designed for faces, this model has learned complex patterns and details that could transfer well to decal generation. The high resolution matches our target 1024x1024 output.\n",
    "\n",
    "3. **MetFaces (1024x1024)**: This model was trained using transfer learning from FFHQ with ADA, demonstrating the effectiveness of the ADA approach for limited data scenarios.\n",
    "\n",
    "For this project, we'll use the **BreCaHAD** model as our primary kickoff point, as it's likely to handle the structural constraints of decal textures well. We'll also experiment with the other models to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up training parameters\n",
    "if IN_COLAB:\n",
    "    # Select pretrained model to use\n",
    "    PRETRAINED_MODEL = os.path.join(MODELS_DIR, \"brecahad.pkl\")\n",
    "    \n",
    "    # Set up training parameters\n",
    "    DATASET_PATH = os.path.join(DATA_DIR, 'dataset/rocket_league_decals')\n",
    "    OUTPUT_DIR = os.path.join(OUTPUTS_DIR, 'training-runs')\n",
    "    \n",
    "    # Training parameters as specified in requirements\n",
    "    GPUS = 1\n",
    "    BATCH_SIZE = 4\n",
    "    AUG = \"ada\"\n",
    "    KIMG = 25000\n",
    "    FP32 = True\n",
    "    \n",
    "    # Create a custom training script with wandb integration\n",
    "    with open('train_with_wandb.py', 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import wandb\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Function to parse training stats\n",
    "def parse_training_stats(stats_file):\n",
    "    if not os.path.exists(stats_file):\n",
    "        return None\n",
    "    \n",
    "    with open(stats_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if not lines:\n",
    "        return None\n",
    "    \n",
    "    # Parse the latest stats\n",
    "    try:\n",
    "        latest_stats = json.loads(lines[-1])\n",
    "        return latest_stats\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Start the training process\n",
    "cmd = [\n",
    "    'python', 'stylegan2-ada-pytorch/train.py',\n",
    "    f'--outdir={sys.argv[1]}',\n",
    "    f'--data={sys.argv[2]}',\n",
    "    f'--gpus={sys.argv[3]}',\n",
    "    f'--batch={sys.argv[4]}',\n",
    "    f'--aug={sys.argv[5]}',\n",
    "    f'--resume={sys.argv[6]}',\n",
    "    f'--kimg={sys.argv[7]}',\n",
    "]\n",
    "\n",
    "if sys.argv[8] == 'True':\n",
    "    cmd.append('--fp32')\n",
    "\n",
    "# Start the process\n",
    "process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "# Monitor the output directory for training stats\n",
    "output_dir = sys.argv[1]\n",
    "last_log_time = 0\n",
    "\n",
    "while process.poll() is None:\n",
    "    # Check for output from the process\n",
    "    output = process.stdout.readline()\n",
    "    if output:\n",
    "        print(output.strip())\n",
    "    \n",
    "    # Check for training stats every 60 seconds\n",
    "    current_time = time.time()\n",
    "    if current_time - last_log_time > 60:\n",
    "        # Look for the training_stats.jsonl file in subdirectories\n",
    "        for root, dirs, files in os.walk(output_dir):\n",
    "            if 'training_stats.jsonl' in files:\n",
    "                stats_file = os.path.join(root, 'training_stats.jsonl')\n",
    "                stats = parse_training_stats(stats_file)\n",
    "                \n",
    "                if stats:\n",
    "                    # Log to wandb\n",
    "                    wandb_stats = {}\n",
    "                    \n",
    "                    # Extract relevant metrics\n",
    "                    if 'tick' in stats:\n",
    "                        wandb_stats['tick'] = stats['tick']\n",
    "                    if 'kimg' in stats:\n",
    "                        wandb_stats['kimg'] = stats['kimg']\n",
    "                    \n",
    "                    # Loss metrics\n",
    "                    for key in stats:\n",
    "                        if key.startswith('Loss/'):\n",
    "                            wandb_stats[key] = stats[key]\n",
    "                    \n",
    "                    # FID score if available\n",
    "                    if 'fid50k_full' in stats:\n",
    "                        wandb_stats['fid50k_full'] = stats['fid50k_full']\n",
    "                    \n",
    "                    # Log to wandb\n",
    "                    wandb.log(wandb_stats)\n",
    "                    \n",
    "                    # Also look for generated images\n",
    "                    fakes_file = os.path.join(root, 'fakes.png')\n",
    "                    if os.path.exists(fakes_file):\n",
    "                        wandb.log({\"generated_samples\": wandb.Image(fakes_file)})\n",
    "                \n",
    "                last_log_time = current_time\n",
    "                break\n",
    "    \n",
    "    # Sleep briefly to avoid high CPU usage\n",
    "    time.sleep(1)\n",
    "\n",
    "# Process any remaining output\n",
    "for output in process.stdout:\n",
    "    print(output.strip())\n",
    "\n",
    "# Final status\n",
    "exit_code = process.wait()\n",
    "print(f\"Training process exited with code {exit_code}\")\n",
    "        \"\"\")\n",
    "    \n",
    "    print(\"Created custom training script with wandb integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the training process\n",
    "if IN_COLAB and os.path.exists(DATASET_PATH) and os.path.exists(PRETRAINED_MODEL):\n",
    "    print(\"Starting StyleGAN2-ADA training...\")\n",
    "    \n",
    "    # Run the custom training script\n",
    "    !python train_with_wandb.py \\\n",
    "        {OUTPUT_DIR} \\\n",
    "        {DATASET_PATH} \\\n",
    "        {GPUS} \\\n",
    "        {BATCH_SIZE} \\\n",
    "        {AUG} \\\n",
    "        {PRETRAINED_MODEL} \\\n",
    "        {KIMG} \\\n",
    "        {str(FP32)}\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "else:\n",
    "    print(\"Cannot start training. Please ensure dataset and pretrained model are available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "This section evaluates the trained model using FID and precision/recall metrics. It includes:\n",
    "- Computing FID score\n",
    "- Computing precision and recall\n",
    "- Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the trained model\n",
    "if IN_COLAB:\n",
    "    # Find the latest network pickle\n",
    "    import glob\n",
    "    \n",
    "    # Look for the latest network pickle in the output directory\n",
    "    network_pickles = glob.glob(f\"{OUTPUT_DIR}/**/network-snapshot-*.pkl\", recursive=True)\n",
    "    if network_pickles:\n",
    "        # Sort by modification time (newest first)\n",
    "        network_pickles.sort(key=os.path.getmtime, reverse=True)\n",
    "        latest_pickle = network_pickles[0]\n",
    "        print(f\"Found latest network pickle: {latest_pickle}\")\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(\"Computing FID and precision/recall metrics...\")\n",
    "        !python stylegan2-ada-pytorch/calc_metrics.py \\\n",
    "            --metrics=fid50k_full,pr50k3_full \\\n",
    "            --network={latest_pickle} \\\n",
    "            --data={DATASET_PATH} \\\n",
    "            --gpus={GPUS}\n",
    "        \n",
    "        # Parse and log metrics\n",
    "        metrics_file = os.path.join(os.path.dirname(latest_pickle), 'metric-fid50k_full.jsonl')\n",
    "        pr_metrics_file = os.path.join(os.path.dirname(latest_pickle), 'metric-pr50k3_full.jsonl')\n",
    "        \n",
    "        if os.path.exists(metrics_file):\n",
    "            with open(metrics_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    fid_metric = json.loads(lines[-1])\n",
    "                    print(f\"FID score: {fid_metric['results']['fid50k_full']}\")\n",
    "                    wandb.log({\"final_fid\": fid_metric['results']['fid50k_full']})\n",
    "        \n",
    "        if os.path.exists(pr_metrics_file):\n",
    "            with open(pr_metrics_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if lines:\n",
    "                    pr_metric = json.loads(lines[-1])\n",
    "                    precision = pr_metric['results']['pr50k3_full_precision']\n",
    "                    recall = pr_metric['results']['pr50k3_full_recall']\n",
    "                    print(f\"Precision: {precision}, Recall: {recall}\")\n",
    "                    wandb.log({\"final_precision\": precision, \"final_recall\": recall})\n",
    "    else:\n",
    "        print(\"No trained network pickles found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Generation\n",
    "\n",
    "This section generates sample 1024×1024 decal textures using the trained model. It includes:\n",
    "- Generating random samples\n",
    "- Visualizing the generated textures\n",
    "- Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate samples\n",
    "if IN_COLAB and 'latest_pickle' in locals() and os.path.exists(latest_pickle):\n",
    "    # Create samples directory\n",
    "    SAMPLES_DIR = os.path.join(OUTPUTS_DIR, 'samples')\n",
    "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "    \n",
    "    # Generate random samples\n",
    "    print(\"Generating random samples...\")\n",
    "    !python stylegan2-ada-pytorch/generate.py \\\n",
    "        --outdir={SAMPLES_DIR} \\\n",
    "        --trunc=0.7 \\\n",
    "        --seeds=0-9 \\\n",
    "        --network={latest_pickle}\n",
    "    \n",
    "    # Display the generated samples\n",
    "    from IPython.display import Image, display\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    sample_files = sorted(glob.glob(f\"{SAMPLES_DIR}/seed*.png\"))\n",
    "    \n",
    "    if sample_files:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for i, sample_file in enumerate(sample_files[:10]):\n",
    "            plt.subplot(2, 5, i+1)\n",
    "            img = plt.imread(sample_file)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Sample {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(SAMPLES_DIR, 'samples_grid.png'))\n",
    "        plt.show()\n",
    "        \n",
    "        # Log samples to wandb\n",
    "        wandb.log({\"generated_samples_grid\": wandb.Image(os.path.join(SAMPLES_DIR, 'samples_grid.png'))})\n",
    "        \n",
    "        # Log individual samples\n",
    "        for i, sample_file in enumerate(sample_files[:10]):\n",
    "            wandb.log({f\"sample_{i+1}\": wandb.Image(sample_file)})\n",
    "    else:\n",
    "        print(\"No samples generated.\")\n",
    "else:\n",
    "    print(\"Cannot generate samples. Please ensure trained model is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Reporting\n",
    "\n",
    "This section generates a markdown summary of the project, including data statistics, training curves, and final metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate summary report\n",
    "if IN_COLAB:\n",
    "    # Create report directory\n",
    "    REPORT_DIR = os.path.join(OUTPUTS_DIR, 'report')\n",
    "    os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Generate markdown report\n",
    "    report_path = os.path.join(REPORT_DIR, 'summary_report.md')\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"# WrapsRL v5 Project Summary Report\\n\\n\")\n",
    "        \n",
    "        # Dataset statistics\n",
    "        f.write(\"## Dataset Statistics\\n\\n\")\n",
    "        stats_file = os.path.join(DATA_DIR, 'dataset_stats.json')\n",
    "        if os.path.exists(stats_file):\n",
    "            with open(stats_file, 'r') as sf:\n",
    "                stats = json.load(sf)\n",
    "                f.write(f\"- Number of images: {stats['num_images']}\\n\")\n",
    "                f.write(f\"- Image size: {stats['image_size']}\\n\")\n",
    "                f.write(f\"- Total dataset size: {stats['total_size_mb']:.2f} MB\\n\")\n",
    "                f.write(f\"- Average image size: {stats['avg_size_kb']:.2f} KB\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"Dataset statistics not available.\\n\\n\")\n",
    "        \n",
    "        # Training configuration\n",
    "        f.write(\"## Training Configuration\\n\\n\")\n",
    "        f.write(f\"- Pretrained model: {os.path.basename(PRETRAINED_MODEL)}\\n\")\n",
    "        f.write(f\"- GPUs: {GPUS}\\n\")\n",
    "        f.write(f\"- Batch size: {BATCH_SIZE}\\n\")\n",
    "        f.write(f\"- Augmentation: {AUG}\\n\")\n",
    "        f.write(f\"- Training duration: {KIMG} kimgs\\n\")\n",
    "        f.write(f\"- FP32: {FP32}\\n\\n\")\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        f.write(\"## Evaluation Metrics\\n\\n\")\n",
    "        if 'latest_pickle' in locals() and os.path.exists(latest_pickle):\n",
    "            metrics_file = os.path.join(os.path.dirname(latest_pickle), 'metric-fid50k_full.jsonl')\n",
    "            pr_metrics_file = os.path.join(os.path.dirname(latest_pickle), 'metric-pr50k3_full.jsonl')\n",
    "            \n",
    "            if os.path.exists(metrics_file):\n",
    "                with open(metrics_file, 'r') as mf:\n",
    "                    lines = mf.readlines()\n",
    "                    if lines:\n",
    "                        fid_metric = json.loads(lines[-1])\n",
    "                        f.write(f\"- FID score: {fid_metric['results']['fid50k_full']}\\n\")\n",
    "            \n",
    "            if os.path.exists(pr_metrics_file):\n",
    "                with open(pr_metrics_file, 'r') as pf:\n",
    "                    lines = pf.readlines()\n",
    "                    if lines:\n",
    "                        pr_metric = json.loads(lines[-1])\n",
    "                        precision = pr_metric['results']['pr50k3_full_precision']\n",
    "                        recall = pr_metric['results']['pr50k3_full_recall']\n",
    "                        f.write(f\"- Precision: {precision}\\n\")\n",
    "                        f.write(f\"- Recall: {recall}\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"Evaluation metrics not available.\\n\\n\")\n",
    "        \n",
    "        # Sample images\n",
    "        f.write(\"## Sample Images\\n\\n\")\n",
    "        samples_grid = os.path.join(SAMPLES_DIR, 'samples_grid.png')\n",
    "        if os.path.exists(samples_grid):\n",
    "            f.write(f\"![Generated Samples]({samples_grid})\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"Sample images not available.\\n\\n\")\n",
    "        \n",
    "        # Wandb link\n",
    "        f.write(\"## Remote Monitoring\\n\\n\")\n",
    "        f.write(f\"Training progress and metrics can be monitored remotely at: {wandb.run.get_url()}\\n\")\n",
    "    \n",
    "    print(f\"Summary report generated at {report_path}\")\n",
    "    \n",
    "    # Display the report\n",
    "    with open(report_path, 'r') as f:\n",
    "        report_content = f.read()\n",
    "    \n",
    "    from IPython.display import Markdown\n",
    "    display(Markdown(report_content))\n",
    "    \n",
    "    # Log report to wandb\n",
    "    wandb.save(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean up and finish\n",
    "if IN_COLAB:\n",
    "    # Stop monitoring\n",
    "    if 'monitoring_active' in globals():\n",
    "        monitoring_active = False\n",
    "        if 'monitor_thread' in globals() and monitor_thread.is_alive():\n",
    "            monitor_thread.join(timeout=1)\n",
    "    \n",
    "    # Finish wandb run\n",
    "    wandb.finish()\n",
    "    \n",
    "    print(\"WrapsRL v5 project completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
